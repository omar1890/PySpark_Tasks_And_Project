{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MrBC530gmg5"
   },
   "source": [
    "Let's start with your project: \n",
    "\n",
    "Are you a data scientist? \n",
    "\n",
    "I think you are an awesome a data scientist.\n",
    "\n",
    "### **Problem** \n",
    "**Our goal is to create a predictive model that can answer the following question:**\n",
    "\n",
    "**What kind of people had a better chance of surviving?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhBfwzBgioTD"
   },
   "source": [
    "**Data about passengers:**\n",
    "*   Name\n",
    "*   Age\n",
    "*   Gender.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIEH8iZqi-sk"
   },
   "source": [
    "## Install and Import Libraries\n",
    "Let's install PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oj1HhvIOY5Yz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDp80mG9jmfU"
   },
   "source": [
    "## Build Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    ".builder\n",
    ".appName(\"Titanic_Prediction\")\n",
    ".getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiqECDzLj1Mg"
   },
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn-hxNggkTqV"
   },
   "source": [
    "You have two datasets: \n",
    "* Train  \n",
    "* Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8-A8M7QmKDJ"
   },
   "source": [
    "Read two datasets: \n",
    "* Train\n",
    "* Test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Mx2qAccBk15y"
   },
   "outputs": [],
   "source": [
    "df_train = spark.read.csv('train.csv',header=True,inferSchema=True)\n",
    "df_test = spark.read.csv('test.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj2ANTnWmSCq"
   },
   "source": [
    "Let's work with train dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5mWJR30lNs5"
   },
   "source": [
    "**Confirm if this is a dataframe or not:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tEYTePrzk9yl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvLJElPrlT4i"
   },
   "source": [
    "**Show 5 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jYwhqvV8lnO0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QIYVxRXlnnw"
   },
   "source": [
    "**Display schema for the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pcvERiICl1Ep"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmE3Wd80l1S6"
   },
   "source": [
    "**Statistical summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cNY0SItol5Mo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.describe().show(truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiFaIEQTl70_"
   },
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSNPOnP8mw2Q"
   },
   "source": [
    "**Display count for the train dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zrtpG11Fl9HM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_6nnTfxm9_x"
   },
   "source": [
    "**Can you answer this question:** \n",
    "\n",
    "**How many people survived, and how many didn't survive?** \n",
    "\n",
    "**Please save data in a variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survived = df_train.groupBy('Survived').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8DUtZXPn46m"
   },
   "source": [
    "**Display your result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0XHAK8ceoCMU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_survived.show() # 1 for survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ygsg7wQqor9a"
   },
   "source": [
    "**Can you display your answer in ratio form?(Hint: Use UDF.)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3uiaN29PoQnf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|Survived|    Survived Ratio|\n",
      "+--------+------------------+\n",
      "|       1|0.3838383838383838|\n",
      "|       0|0.6161616161616161|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_survived.select('Survived',(col(\"count\")/df_train.count()).alias('Survived Ratio')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7Aker_lp1h4"
   },
   "source": [
    "**Can you get the number of males and females?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XllkDlo3ongJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.groupBy('Sex').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the average number of survivors of each gender?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|   Sex|      avg(Survived)|\n",
      "+------+-------------------+\n",
      "|female| 0.7420382165605095|\n",
      "|  male|0.18890814558058924|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.groupBy('Sex').agg(avg('Survived')).show()#groupBy('Sex','Survived').count().select('Sex','Survived',col('count')/df_train.count()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHFaJ15zqtEV"
   },
   "source": [
    "\n",
    "\n",
    "**2. What is the number of survivors of each gender?**\n",
    "\n",
    "(Hint: Group by the \"sex\" column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NUikH7MUqdKq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|   Sex|Survived|count|\n",
      "+------+--------+-----+\n",
      "|  male|       0|  468|\n",
      "|female|       1|  233|\n",
      "|female|       0|   81|\n",
      "|  male|       1|  109|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.groupBy('Sex','Survived').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCEdYNdArtRN"
   },
   "source": [
    "**Create temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YjlK6HDUqsI5"
   },
   "outputs": [],
   "source": [
    "df_train.createOrReplaceTempView('titanic_train_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXNePifnshHr"
   },
   "source": [
    "**How many people survived, and how many didn't survive? By SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0HxfPRTMslqk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|Survived|count(Survived)|\n",
      "+--------+---------------+\n",
      "|       1|            342|\n",
      "|       0|            549|\n",
      "+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select Survived,COUNT(Survived)\n",
    "            from titanic_train_data\n",
    "            GROUP BY Survived\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVCdY6EasFWV"
   },
   "source": [
    "**Can you display the number of survivors from each gender as a ratio?**\n",
    "\n",
    "(Hint: Group by \"sex\" column.)\n",
    "\n",
    "**Can you do this via SQL?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7xQc3pUUr3HF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|   Sex|Survived|\n",
      "+------+--------+\n",
      "|female|     314|\n",
      "|  male|     577|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select Sex,COUNT(Survived) as Survived\n",
    "            from titanic_train_data\n",
    "            GROUP BY Sex\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6QXc5V8uu3Y"
   },
   "source": [
    "**Display a ratio for p-class:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Mscs2mDFdFsD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-------------+\n",
      "|Pclass|Pclass_ratio|sum(Survived)|\n",
      "+------+------------+-------------+\n",
      "|     1|        0.63|          136|\n",
      "|     3|        0.24|          119|\n",
      "|     2|        0.47|           87|\n",
      "+------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select Pclass,round(sum(Survived)/COUNT(Pclass),2 ) as Pclass_ratio,sum(Survived)\n",
    "            from titanic_train_data\n",
    "            GROUP BY Pclass\"\"\").show()\n",
    "#Stuck Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX0klxwAvg6J"
   },
   "source": [
    "**Let's take a break and continue after this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ctM9t8atxJl"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CfanZTCt6Wk"
   },
   "source": [
    "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8Nm8S1K0r4uY"
   },
   "outputs": [],
   "source": [
    "df_all = df_train.union(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI7AD8FLz3iO"
   },
   "source": [
    "**Display count:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "I4rd9e6nzzr5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVQlr9vDy7Y4"
   },
   "source": [
    "**Temporary view PySpark:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "s_WERAL8wvJa"
   },
   "outputs": [],
   "source": [
    "df_all.createOrReplaceTempView('all_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R4Miuy0z_uP"
   },
   "source": [
    "**Can you define the number of null values in each column?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBX8cJ000aqe"
   },
   "source": [
    "**Create Dataframe for null values**\n",
    "\n",
    "1. Column\n",
    "2. Number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ITmyUelNxjJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|265|    0|    0|     0|   0| 1021|       3|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.select([count(when(col(c).isNull() , c)).alias(c) for c in df_all.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuKrOi5a0-Ma"
   },
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txa8NZIO1JaP"
   },
   "source": [
    "**Can you show me the name column from your temporary table?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "m7yXqJoJy35k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "|Futrelle, Mrs. Ja...|\n",
      "|Allen, Mr. Willia...|\n",
      "|    Moran, Mr. James|\n",
      "|McCarthy, Mr. Tim...|\n",
      "|Palsson, Master. ...|\n",
      "|Johnson, Mrs. Osc...|\n",
      "|Nasser, Mrs. Nich...|\n",
      "|Sandstrom, Miss. ...|\n",
      "|Bonnell, Miss. El...|\n",
      "|Saundercock, Mr. ...|\n",
      "|Andersson, Mr. An...|\n",
      "|Vestrom, Miss. Hu...|\n",
      "|Hewlett, Mrs. (Ma...|\n",
      "|Rice, Master. Eugene|\n",
      "|Williams, Mr. Cha...|\n",
      "|Vander Planke, Mr...|\n",
      "|Masselmani, Mrs. ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select Name from all_data\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F0F9cTZ2Cuz"
   },
   "source": [
    "**Run this code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "0kx6OcB-2BBT"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "combined = df_all.withColumn('Title',F.regexp_extract(F.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "combined.createOrReplaceTempView('combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbZeUWS12r59"
   },
   "source": [
    "**Display the title and count \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hGkFMtlp1FAI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|   title|count(title)|\n",
      "+--------+------------+\n",
      "|     Don|           1|\n",
      "|    Miss|         257|\n",
      "|Countess|           2|\n",
      "|     Col|           4|\n",
      "|     Rev|           9|\n",
      "|    Lady|           2|\n",
      "|  Master|          56|\n",
      "|     Mme|           1|\n",
      "|    Capt|           2|\n",
      "|      Mr|         786|\n",
      "|      Dr|          11|\n",
      "|     Mrs|         186|\n",
      "|     Sir|           2|\n",
      "|Jonkheer|           2|\n",
      "|    Mlle|           4|\n",
      "|   Major|           3|\n",
      "|      Ms|           1|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select title,count(title) from combined group by title\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLBQDKYu4JOa"
   },
   "source": [
    "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rjnx5l5r2Qaf"
   },
   "outputs": [],
   "source": [
    "mapping = {'Miss':'Miss','Mrs':'Mrs','Mr':'Mr','Master':'Master','Ms':'Ms','Dr':'rare', 'Rev':'rare', 'Major':'rare', 'Col':'rare', 'Mlle':'rare', 'Capt':'rare', 'Don':'rare', 'Jonkheer':'rare', 'Countess':'rare', 'Ms':'rare', 'Sir':'rare', 'Lady':'rare','Mme':'rare'}\n",
    "# df_rare = combined.replace(to_replace=mapping,subset=['Title'])\n",
    "# df_rare.select('Title').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wrE95Cv7Oqh"
   },
   "source": [
    "**Run the function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HdDbWuDl7Pf4"
   },
   "outputs": [],
   "source": [
    "def impute_title(title):\n",
    "    return mapping[title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5EQVIhK7a9R"
   },
   "source": [
    "**Apply the function on \"Title\" column using UDF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rBAiIOn77XFa"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "impute_title_udf = udf(lambda title:impute_title(title))\n",
    "new_df = combined.withColumn('Title',impute_title_udf(col('Title')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn8ewllf7kiV"
   },
   "source": [
    "**Display \"Title\" from table and group by \"Title\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "J9sjQb084GU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "| title|count(title)|\n",
      "+------+------------+\n",
      "|  rare|          44|\n",
      "|  Miss|         257|\n",
      "|Master|          56|\n",
      "|    Mr|         786|\n",
      "|   Mrs|         186|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.createOrReplaceTempView('combined')\n",
    "spark.sql(\"\"\"select title,count(title) from combined group by title\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H45QNLj9vJp"
   },
   "source": [
    "## **Preprocessing Age**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwRAhumK-u__"
   },
   "source": [
    "**Based on the age mean, you will fill in the missing age values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eXYSVzvl4z63"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "age_avg = (combined.agg(avg('age')).collect())\n",
    "new_df = new_df.na.fill(np.round(age_avg[0][0],0),subset=['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLPivde8_GI-"
   },
   "source": [
    "**Fill missing age with age mean:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "lBgW8aFD90PA"
   },
   "outputs": [],
   "source": [
    "# i do it in on step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGsnUz-m_P95"
   },
   "source": [
    "## **Preprocessing Embarked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHbbamcXMSYP"
   },
   "source": [
    "**Select Embarked, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "v-lRu5vc_FW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|Embarked|Embarked_Count|\n",
      "+--------+--------------+\n",
      "|       S|           962|\n",
      "|       C|           253|\n",
      "|       Q|           111|\n",
      "|    null|             0|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_Embarked = spark.sql(\"\"\"select Embarked , count(Embarked) as Embarked_Count from combined group by Embarked order by Embarked_Count desc \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1qf5u2IOQrx"
   },
   "source": [
    "**Show groupped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSFNDTNg_erb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzQWYgKBMrbp"
   },
   "source": [
    "**Get the groupped_Embarked:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu46QWrn_gCX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLYj4F7E_iqb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8vhoEs8N2w_"
   },
   "source": [
    "**Fill missing values with Top 'S' of grouped_Embarked:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "LdzQCRud_mAa"
   },
   "outputs": [],
   "source": [
    "new_df= new_df.na.fill('S',subset=['Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEcdV5Vb_qR_"
   },
   "source": [
    "## **Preprocessing Cabin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BQzPs7tqhpA"
   },
   "source": [
    "**Replace \"cabin\" column with first char from the string:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4b6L5pK0_nQz"
   },
   "outputs": [],
   "source": [
    "prep_df = new_df.withColumn('cabin',substring('cabin',0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H8XshnYj4k2"
   },
   "source": [
    "**Show the result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJUQwnG1Oj2U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzSDsWsUj9Im"
   },
   "source": [
    "**Create the temporary view:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "MR7CXTY7_tMJ"
   },
   "outputs": [],
   "source": [
    "prep_df.createOrReplaceTempView('prep_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv7lfQFkrLlN"
   },
   "source": [
    "**Select \"Cabin\" column, count Cabin column, Group by \"Cabin\" column, Order By count DESC**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "A0tZG_mvrKXv"
   },
   "outputs": [],
   "source": [
    "cabin_c=spark.sql(\"\"\"select Cabin , count(Cabin) as cabin_count from prep_data group by Cabin order by cabin_count desc\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GR6j0LOsB4y"
   },
   "source": [
    "**Fill missing values with \"U\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Cabin: string, cabin_count: bigint]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin_c.na.fill('U',subset=['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df=prep_df.na.fill('U',subset=['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|cabin|Embarked| Title|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|    U|       S|    Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|    C|       C|   Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|    U|       S|  Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|    C|       S|   Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|    U|       S|    Mr|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|30.0|    0|    0|          330877| 8.4583|    U|       Q|    Mr|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|    E|       S|    Mr|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|    U|       S|Master|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|    U|       S|   Mrs|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|    U|       C|   Mrs|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|    G|       S|  Miss|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|    C|       S|  Miss|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|    U|       S|    Mr|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|    U|       S|    Mr|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|    U|       S|  Miss|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|    U|       S|   Mrs|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|    U|       Q|Master|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|30.0|    0|    0|          244373|   13.0|    U|       S|    Mr|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|    U|       S|   Mrs|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|30.0|    0|    0|            2649|  7.225|    U|       C|   Mrs|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "mwq5CHEz_up_"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRnhA_5-0Hi4"
   },
   "source": [
    "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is ‘frequencyDesc’.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RIKlOX71GQ-"
   },
   "source": [
    "**StringIndexer(inputCol=None, outputCol=None)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0c_Hf_b0R12"
   },
   "source": [
    "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWfXaZ0I4dXD"
   },
   "source": [
    "____________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FsiLsd9452v"
   },
   "source": [
    "**VectorAssembler: VectorAssembler(*, inputCols=None, outputCol=None) A feature transformer that merges multiple columns into a vector column.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU8DeZfh7JIo"
   },
   "source": [
    "**Use randomSplit function and split data to x_train, and X_test with 80% and 20% Consecutive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1205,
     "status": "ok",
     "timestamp": 1633434787166,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "8C11xf1iAzKp",
    "outputId": "750a1221-42b8-48cb-b754-1836240acad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1060 rows in the training set, and 269 in the test set.\n"
     ]
    }
   ],
   "source": [
    "combined = prep_df\n",
    "X_train, X_test = combined.randomSplit([0.8,0.2],seed=0)\n",
    "print(f\"There are {X_train.count()} rows in the training set, and {X_test.count()} in the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "QwmliG5ity8y"
   },
   "outputs": [],
   "source": [
    "# X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1633434787170,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "4D7_Xo9msJIa",
    "outputId": "4d4b796e-56f4-4f6b-d905-a97a66fc03d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Sex', 'Ticket', 'cabin', 'Embarked', 'Title']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalColumns = [col for (col, dtype) in X_train.dtypes\n",
    "                   if dtype == \"string\"]\n",
    "categoricalColumns           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1633434787172,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "0_d5cS6guemj",
    "outputId": "2161943d-64c7-4599-bad1-3837c13f535a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Ticket', 'cabin', 'Embarked', 'Title']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalColumns.remove(\"Name\")\n",
    "categoricalColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "X9YOgg7nutjP"
   },
   "outputs": [],
   "source": [
    "# for col in categoricalColumns:\n",
    "#   X_train.select(col).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1633434787175,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "4TFWsRdlvN2W",
    "outputId": "daf41341-e71d-491b-aa57-0d5a3610de12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_Index', 'Ticket_Index', 'cabin_Index', 'Embarked_Index', 'Title_Index']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexOutputColumns = [x + \"_Index\" for x in categoricalColumns]\n",
    "indexOutputColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1633434787177,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "2NEMhlsSvTe2",
    "outputId": "aa06df99-7219-4f7e-88cd-692307ee435a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_OHE', 'Ticket_OHE', 'cabin_OHE', 'Embarked_OHE', 'Title_OHE']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oheOutputColumns = [x + \"_OHE\" for x in categoricalColumns]\n",
    "oheOutputColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "oTSKITy4vWbF"
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=categoricalColumns,\n",
    "                             outputCols=indexOutputColumns,\n",
    "                             handleInvalid='skip')\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputColumns,\n",
    "                          outputCols=oheOutputColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1633434787181,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "gDfS1vptvb4d",
    "outputId": "4fd2319d-afeb-4878-b396-eda82517aff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericColumns = [field for (field,dataType) in X_train.dtypes\n",
    "              if ((dataType=='double'or dataType=='int')& (field!='Survived'))]\n",
    "numericColumns.remove('PassengerId')\n",
    "numericColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1633434787563,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "xXnkXOXZwG7a",
    "outputId": "0ad642cf-b13f-4e00-eb77-db08132e602c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_OHE',\n",
       " 'Ticket_OHE',\n",
       " 'cabin_OHE',\n",
       " 'Embarked_OHE',\n",
       " 'Title_OHE',\n",
       " 'Pclass',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs = oheOutputColumns + numericColumns\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0mvTu0f0yRN7"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJQvmFai72O7"
   },
   "source": [
    "**Build RandomForestClassifier model and use pipeline to fit and transform then display \"prediction, Survived, features\" columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "MzIDSJzgA035"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(featuresCol='features', labelCol='Survived', predictionCol='prediction', maxDepth=5)\n",
    "pipeline =Pipeline(stages = [stringIndexer,oheEncoder,vecAssembler,rfc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "OEFHdBNMz-Ea"
   },
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "8hd8RUtk0EsW"
   },
   "outputs": [],
   "source": [
    "predDF = pipelineModel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1633434794814,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "ox8VBcCG0IaD",
    "outputId": "677107d2-020e-4c1b-c1fa-8d21f7a8a93f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+\n",
      "|            features|Survived|prediction|\n",
      "+--------------------+--------+----------+\n",
      "|(638,[0,119,619,6...|       0|       0.0|\n",
      "|(638,[381,619,628...|       1|       1.0|\n",
      "|(638,[480,619,627...|       0|       0.0|\n",
      "|(638,[309,621,627...|       1|       1.0|\n",
      "|(638,[0,382,619,6...|       1|       0.0|\n",
      "+--------------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select('features','Survived','prediction').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSXEI8-r8bKY"
   },
   "source": [
    "**Use MulticlassClassificationEvaluator and set the \"labelCol\" to \"Survived\",  \"predictionCol\" to \"prediction\", \"metricName\" to \"accuracy\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Rl0UAKCaBDO-"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "MCE = MulticlassClassificationEvaluator(predictionCol='prediction',\n",
    "                                        labelCol='Survived',\n",
    "                                        metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1633434795541,
     "user": {
      "displayName": "Mohammad Hanafy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Giuy37GDlS2vNiXT3hDh1ABJSsvYFzCmrgE5v69dA=s64",
      "userId": "00084983512555869605"
     },
     "user_tz": -120
    },
    "id": "K1Ri0TIM1Kw2",
    "outputId": "bded6dcf-760a-449d-84cf-085db48c68b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826530612244898"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = MCE.evaluate(predDF)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practical_work.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
